<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Methods’ overview &mdash; IDPET 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dimensionality reduction based on distance-based features" href="dr_cadist.html" />
    <link rel="prev" title="Dimensionality reduction based on angular-based features" href="dr_phipsi.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            IDPET
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="demo.html">Demo</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Global_analysis.html">Global analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="local_analysis.html">Local analysis</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="dimensional_reduction.html">Dimensionality Reduction Analysis</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="dr_phipsi.html">Dimensionality reduction based on angular-based features</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Methods’ overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#t-sne-t-distributed-stochastic-neighbor-embedding">t-SNE (t-distributed Stochastic Neighbor Embedding.)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#umap-uniform-manifold-approximation-projection">UMAP (Uniform Manifold Approximation &amp; Projection)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pca-principal-component-analysis">PCA (Principal Component Analysis)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kernelpca-kernel-principal-component-analysis">KernelPCA (Kernel-Principal Component Analysis)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dr_cadist.html">Dimensionality reduction based on distance-based features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="comparing_ensambles.html">Comparing Ensambles</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_analysis.html">ensemble_analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble.html">ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization.html">visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="comparison.html">ensemble_compariosn</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">IDPET</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="demo.html">Demo</a></li>
          <li class="breadcrumb-item"><a href="dimensional_reduction.html">Dimensionality Reduction Analysis</a></li>
      <li class="breadcrumb-item active">Methods’ overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/method_overview.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="methods-overview">
<h1>Methods’ overview<a class="headerlink" href="#methods-overview" title="Permalink to this heading"></a></h1>
<section id="t-sne-t-distributed-stochastic-neighbor-embedding">
<h2>t-SNE (t-distributed Stochastic Neighbor Embedding.)<a class="headerlink" href="#t-sne-t-distributed-stochastic-neighbor-embedding" title="Permalink to this heading"></a></h2>
<p>t-SNE is a technique that reduces the dimensionality of data while preserving relationships between data points. It minimizes the Kullback-Leibler divergence between the joint probabilities of the high-dimensional data and its low-dimensional embedding.
The process begins by randomly projecting data points into a low-dimensional space. These points are gradually adjusted, forming distinct clusters. At each step, points are attracted to nearby points and repelled from distant ones based on similarity measures.</p>
<p>Steps involved in t-SNE:</p>
<p>1- <strong>Calculate Similarities:</strong>
The similarity between points is calculated by measuring the distance between them in the high-dimensional space. A normal distribution is centered on each point to measure the “unscaled similarity.”</p>
<p>2- <strong>Normalize Similarities:</strong>
The unscaled similarities are normalized so that they sum to 1. t-SNE averages the similarity scores for each pair of points, forming a similarity matrix.</p>
<p>3- <strong>Low-Dimensional Projection:</strong>
The points are projected into a low-dimensional space, and t-distribution is used to calculate similarity scores in this space.</p>
<p>4- <strong>Iterative Optimization:</strong>
t-SNE iteratively moves the points in the low-dimensional space to minimize the difference between the high-dimensional and low-dimensional similarity matrices.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analysis</span><span class="o">.</span><span class="n">reduce_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;tsne&#39;</span><span class="p">,</span> <span class="n">perplexity_vals</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">circular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">range_n_clusters</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<div class="admonition-perplexity-vals admonition">
<p class="admonition-title">perplexity_vals</p>
<p>Perplexity in t-SNE controls the number of nearest neighbors considered when calculating joint probabilities. Adjusting perplexity affects cluster structure:</p>
<p><strong>Higher Perplexity:</strong> Considers more neighbors, resulting in larger, more spread-out clusters and a more global view of the data. Distant points may be grouped together.</p>
<p><strong>Lower Perplexity:</strong> Focuses on local structures, forming smaller, denser clusters. However, too low of a value can overemphasize local patterns, while too high can blur cluster boundaries.</p>
</div>
<div class="admonition-metric admonition">
<p class="admonition-title">metric</p>
<p>str, optional-Metric to use. Default is “euclidean”.</p>
<p>This parameter specifies the distance measure to be used for calculating the similarities between points in the original dataset.
The choice of metric can influence the result of the embedding as it determines how the distances between points are evaluated.</p>
</div>
<div class="admonition-circular admonition">
<p class="admonition-title">circular</p>
<p>bool, optional-Whether to use circular metrics. Default is False.</p>
<p>This parameter, if present, could indicate whether distance calculation should consider a circular or cyclic structure.
For example, if working with data that have a periodic nature (such as angles ranging from 0 to 360 degrees), using a circular metric can be useful for accurately capturing the relationships between points.</p>
</div>
<div class="admonition-n-components admonition">
<p class="admonition-title">n_components</p>
<p>int, optional-Number of dimensions of the embedded space. Default is 2.</p>
<p>This parameter specifies the number of dimensions in which one wants to reduce the data.</p>
</div>
<div class="admonition-learning-rate admonition">
<p class="admonition-title">learning_rate</p>
<p>float, optional-Learning rate. Default is ‘auto’.</p>
<p>The learning rate, typically between 10.0 and 1000.0, controls how quickly an embedding is modified in each iteration. By adjusting it, one can regulate the convergence speed and the quality of the final embedding. A higher learning rate accelerates optimization and may lead to overly rapid adaptations that overlook certain data structures, making the visualization less stable.
Conversely, a too low value risks slowing down the algorithm’s convergence. The ‘auto’ option sets the learning_rate to max(N / early_exaggeration / 4, 50) where N is the sample size. See the <a class="reference external" href="https://scikit-learn.org/1.5/modules/generated/sklearn.manifold.TSNE.html">documentation</a>.</p>
</div>
<div class="admonition-range-n-clusters admonition">
<p class="admonition-title">range_n_clusters</p>
<p>list[int], optional-Range of cluster values. Default is range(2, 10, 1).</p>
<p>This parameter refers to the range of possible numbers of clusters one wishes to consider in the analysis.</p>
</div>
</section>
<section id="umap-uniform-manifold-approximation-projection">
<h2>UMAP (Uniform Manifold Approximation &amp; Projection)<a class="headerlink" href="#umap-uniform-manifold-approximation-projection" title="Permalink to this heading"></a></h2>
<p>UMAP (Uniform Manifold Approximation and Projection) is a non-linear dimensionality reduction algorithm that preserves the topological structure of high-dimensional data. It calculates similarity scores to identify clusters and maintains these relationships in the low-dimensional space. By adjusting the <cite>n_neighbors</cite> parameter, UMAP balances local and global structure.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analysis</span><span class="o">.</span><span class="n">reduce_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;umap&#39;</span><span class="p">,</span>  <span class="n">n_neighbors</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span>  <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">circular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">range_n_clusters</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>UMAP has several hyperparameters that can significantly impact the resulting embedding:</p>
<div class="admonition-n-neighbors admonition">
<p class="admonition-title">n_neighbors</p>
<p>int, number of  nearest neighbors.[Default is 15].</p>
<p>This parameter controls how UMAP balances the local and global structure in the data.
It does this by limiting the size of the local neighborhood UMAP will consider when learning the structure of the data manifold.
Lower values of <em>n_neighbors</em> will force UMAP to focus on very local structures (potentially at the expense of the overall view), while higher values will make UMAP consider larger neighborhoods around each point when estimating the data manifold structure, losing structural details to gain a broader view of the data.</p>
</div>
<div class="admonition-min-dist admonition">
<p class="admonition-title">min_dist</p>
<p>float, optional-Minimum distance. [Default is 0.1].</p>
<p>This parameter provides the minimum distance that points can have in the low-dimensional representation.
This means that lower values of <em>min_dist</em> will lead to tighter clustering, potentially resulting in a loss of overall data vision.
In this case, even small variations in the data can become overly emphasized.</p>
<p>Conversely, higher values of <em>min_dist</em> will prevent UMAP from identifying distinct clusters, instead focusing on the overall structure.
This can lead to a loss of important details in the local relationships between points, resulting in a representation that, while preserving the general topology, lacks precision in detail.</p>
</div>
<div class="admonition-num-dim admonition">
<p class="admonition-title">num_dim</p>
<p>int, optional-Number of components.[Default is 2]</p>
<p>This parameter determines the dimensionality of the reduced space in which we will embed the data.</p>
</div>
<div class="admonition-metric admonition">
<p class="admonition-title">metric</p>
<p>str, optional-Metric to use.[Default is “euclidean”].</p>
<p>The “metric” parameter in UMAP controls how distances are calculated in the input data space, and naturally, the choice of metric depends on the specific characteristics of the data and the analytical objectives.</p>
<p>[For a comprehensive documentation of the possible metrics, you can consult the following: <a class="reference external" href="https://umap-learn.readthedocs.io/en/latest/parameters.html#metric">link</a>]</p>
<ul class="simple">
<li><p>Euclidean: This metric is based on the formula of the square root of the sum of the squares of the differences between the coordinates of the points. <em>It is commonly used when working with data that can be represented in a Euclidean space.</em></p></li>
<li><p>Canberra: This metric calculates the distance as the sum of the absolute differences between the coordinates of the points divided by the sum of the coordinates of the points themselves. <em>It is suitable for data with very different value ranges and is effective in capturing covariance between variables. This makes it useful for analyzing multivariate data.</em></p></li>
<li><p>Mahalanobis: A generalization of the Euclidean distance, this metric takes into account the covariance between variables. <em>It is particularly useful when working with multivariate data and when it is desired to consider the correlation between variables.</em></p></li>
<li><p>Cosine: This metric measures the angle between two vectors, rather than their magnitude. <em>It is suitable for situations where the direction of the vectors is more important than their length.</em></p></li>
</ul>
</div>
<div class="admonition-range-n-clusters admonition">
<p class="admonition-title">range_n_clusters</p>
<p>list[int], optional-Range of cluster values. Default is range(2, 10, 1).</p>
<p>This parameter refers to the range of possible numbers of clusters one wishes to consider in the analysis.</p>
</div>
</section>
<section id="pca-principal-component-analysis">
<h2>PCA (Principal Component Analysis)<a class="headerlink" href="#pca-principal-component-analysis" title="Permalink to this heading"></a></h2>
<p>PCA is a dimensionality reduction technique based on the decomposition of the eigenvectors of the covariance matrix of high-dimensional data, aiming to identify a set of components that capture the maximum variance present in the data.</p>
<p>To achieve this, PCA projects the original data onto a new coordinate system defined by these principal components. The first principal component corresponds to the direction with the highest variance in the data, the second principal component to the direction with the second-highest variance, and so forth.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analysis</span><span class="o">.</span><span class="n">reduce_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">num_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition-num-dim admonition">
<p class="admonition-title">num_dim</p>
<p>int, optional-Number of components to keep. [Default is 10]</p>
<p>As the sole parameter, <em>“num_dim”</em> is optional and indicates the number of components to retain in the transformed dataset.
A too high value of the “num_dim” parameter could result in retaining too many principal components, leading to a less significant reduction in dimensionality and potentially preserving noise or irrelevant information.
Conversely, a too low value might excessively reduce the dimensionality of the data, causing the loss of important information.</p>
</div>
</section>
<section id="kernelpca-kernel-principal-component-analysis">
<h2>KernelPCA (Kernel-Principal Component Analysis)<a class="headerlink" href="#kernelpca-kernel-principal-component-analysis" title="Permalink to this heading"></a></h2>
<p>Kernel Principal Component Analysis (KPCA) using the scikit-learn library to study various properties of conformational ensembles. KPCA is particularly effective for analyzing non-linear features, such as angular data with periodic properties. To handle angular data appropriately, we transform each angle into its sine and cosine components, capturing the inherent circular nature of the data. Using these transformed values, we construct the kernel matrix by calculating pairwise distances between the data points with a custom kernel function. This procedure allows us to preserve the periodic nature of the angles and effectively analyze the data in a lower-dimensional space, providing insights into the conformational properties of the ensembles.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analysis</span><span class="o">.</span><span class="n">reduce_features</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;kpca&#39;</span><span class="p">,</span> <span class="n">num_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition-num-dim admonition">
<p class="admonition-title">num_dim</p>
<p>Number of components to keep. Default is 10.</p>
</div>
<div class="admonition-gamma admonition">
<p class="admonition-title">gamma</p>
<p>Kernel coefficient. Default is None. If gamma is None, then it is set to 1/n_features</p>
<p>This parameter defines the influence of individual data points in the kernel function. Specifically, it acts as a scaling factor for the distances between data points when using kernels such as the Radial Basis Function (RBF) or Gaussian kernel. A low value of gamma means that distant points have more influence, leading to smoother decision boundaries, while a high value of gamma makes the influence more localized, resulting in more complex boundaries. The default value is typically <cite>1/n_features</cite>, where <cite>n_features</cite> is the number of features in the dataset, but this can be adjusted based on the specific characteristics of the data.</p>
</div>
<div class="admonition-circular admonition">
<p class="admonition-title">circular</p>
<p>Indicates whether to use circular metrics. This should be set to True when analyzing angular data. The default value is False.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dr_phipsi.html" class="btn btn-neutral float-left" title="Dimensionality reduction based on angular-based features" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dr_cadist.html" class="btn btn-neutral float-right" title="Dimensionality reduction based on distance-based features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Hamidreza Ghafouri, Giacomo Janson.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>